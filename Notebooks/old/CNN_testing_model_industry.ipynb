{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import conv_layer, max_pool_2x2, full_layer\n",
    "\n",
    "MINIBATCH_SIZE = 50\n",
    "STEPS = 5000\n",
    "\n",
    "home = os.getcwd().split('AUT-CNN-TUB')[0]\n",
    "test_path  = os.path.join(home,'AUT-CNN-TUB/Data/TF_Images_industry_28/test/')\n",
    "train_path = os.path.join(home,'AUT-CNN-TUB/Data/TF_Images_industry_28/train/')\n",
    "validate_path = os.path.join(home,'AUT-CNN-TUB/Data/TF_Images_Validation_28/train/')\n",
    "\n",
    "model_path  = os.path.join(home,'AUT-CNN-TUB', 'Data', 'Models', 'model_2018-08-12_01-42.ckpt')\n",
    "\n",
    "\n",
    "labels = ['01.0', '02.0', '03.0', '04.0', '05.0', '06.0', '07.1', '07.2',\n",
    "         '08.0', '09.0','10.0','11.0', '12.0','13.0','14.0', '15.0']\n",
    "position_dict = {k: v for v, k in enumerate(labels)}\n",
    "label_dict = {v : k  for v, k in enumerate(labels)}\n",
    "\n",
    "def label_to_binary(position_dict, label):\n",
    "    z = np.zeros(len(position_dict), dtype=int)\n",
    "    z[position_dict[label]] = 1 \n",
    "    return z\n",
    "\n",
    "def next_batch(path, size, GRBtoGray=False, flatten=False):\n",
    "    \n",
    "    data_path = os.path.join(path, '*g')  # ???\n",
    "    files = glob.glob(data_path)\n",
    "    num_imag = len(files)\n",
    "    Data = np.arange(0, num_imag)\n",
    "    batchindices = np.random.choice(Data, size=size,\n",
    "                                    replace=False)  # Zufallsstichprobe; reihenfolge beliebig; ohne zurÃ¼ckl.\n",
    "\n",
    "    label_list =[]\n",
    "    img_list = []\n",
    "    for i, file_path in enumerate(files):\n",
    "        if i in batchindices:\n",
    "            label_str = file_path.split('/')[-1][:4]\n",
    "            label_bin = label_to_binary(position_dict, label_str)\n",
    "\n",
    "            if GRBtoGray == True:\n",
    "                img = cv2.imread(file_path, flags=0)\n",
    "            else:\n",
    "                img = cv2.imread(file_path, flags=1)\n",
    "\n",
    "            if flatten == True:\n",
    "                img_list.append(img.flatten())\n",
    "                label_list.append(label_bin)\n",
    "            else:\n",
    "                img_list.append(img)\n",
    "                label_list.append(label_bin)\n",
    "\n",
    "    img_list = np.array(img_list)\n",
    "    label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "    return img_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataGetter:\n",
    "    def __init__(self, path, GRBtoGray=False, flatten=False): \n",
    "        self.path  = path\n",
    "        self.GRBtoGray  = GRBtoGray\n",
    "        self.flatten  = flatten\n",
    "        self.batchindices = None\n",
    "        \n",
    "        self.data_path = os.path.join(self.path, '*g') \n",
    "        self.files = glob.glob(self.data_path)\n",
    "        self.num_imag = len(self.files)\n",
    "        self.Data = list(range(0, self.num_imag))\n",
    "\n",
    "    def get_batch(self,size):\n",
    "        \n",
    "        if len(self.Data) > size:\n",
    "            self.batchindices = list(np.random.choice(self.Data, size=size, replace=False))\n",
    "            for x in self.batchindices:\n",
    "                self.Data.remove(x) \n",
    "                \n",
    "        elif len(self.Data) == size:\n",
    "            self.batchindices = np.random.choice(self.Data, size=size, replace=False)  \n",
    "            self.Data = list(range(0, self.num_imag))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.batchindices = np.random.choice(self.Data, size=len(self.Data), replace=False)  \n",
    "            self.Data = list(range(0, self.num_imag))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        label_list =[]\n",
    "        img_list = []\n",
    "        file_name_list = []\n",
    "        for i, file_path in enumerate(self.files):\n",
    "            if i in self.batchindices:\n",
    "                label_str = file_path.split('/')[-1][:4]\n",
    "                label_bin = label_to_binary(position_dict, label_str)\n",
    "\n",
    "                if self.GRBtoGray == True:\n",
    "                    img = cv2.imread(file_path, flags=0)\n",
    "                else:\n",
    "                    img = cv2.imread(file_path, flags=1)\n",
    "\n",
    "                if self.flatten == True:\n",
    "                    img_list.append(img.flatten())\n",
    "                    label_list.append(label_bin)\n",
    "                    file_name_list.append(file_path.split('/')[-1])\n",
    "                else:\n",
    "                    img_list.append(img)\n",
    "                    label_list.append(label_bin)\n",
    "                    file_name_list.append(file_path.split('/')[-1])\n",
    "\n",
    "        img_list = np.array(img_list)\n",
    "        label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "        return img_list, label_list, file_name_list\n",
    "    \n",
    "test_img = DataGetter(test_path, False, False)\n",
    "train_img = DataGetter(train_path, False, False)\n",
    "validate_img = DataGetter(validate_path, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jeronimo/git/AUT-CNN-TUB/Data/Models/model_2018-08-12_01-42.ckpt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-40dbbaa4fc17>:21: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/jeronimo/git/AUT-CNN-TUB/Data/Models/model_2018-08-12_01-42.ckpt\n",
      "test accuracy: 0.999587893486023\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(position_dict)])\n",
    "\n",
    "#x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "conv1 = conv_layer(x, shape=[5, 5, 3, 64])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 64, 128])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*128])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, len(position_dict))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "    # Initialize v1 since the saver will not.\n",
    "    #v1.initializer.run()\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    X_batch, y_batch, file_name = test_img.get_batch(len(os.listdir(test_path)))\n",
    "\n",
    "    test_accuracy = np.mean(sess.run(accuracy, feed_dict={x: X_batch, y_: y_batch, keep_prob: 1.0}))\n",
    "\n",
    "    print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jeronimo/git/AUT-CNN-TUB/Data/Models/model_2018-08-12_01-42.ckpt\n",
      "test accuracy: 1.0\n",
      "12.0 ['07.2.0.1.0286.jpg']\n",
      "[[-121.34664    57.176903   51.113987   32.083584   11.623911  -72.64748\n",
      "  -234.09311   338.23126  -103.83141   -48.859947  -95.67986    30.14906\n",
      "   349.08615   313.7421    109.25653   -45.553074]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 ['07.2.0.1.0439.jpg']\n",
      "[[-287.07275   -11.765439 -109.04011   122.90336  -248.1601     39.83005\n",
      "  -120.81148   304.56198  -234.69727    16.346197 -100.18645   -53.987328\n",
      "   333.78964   113.118965  257.248    -141.34444 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(position_dict)])\n",
    "\n",
    "#x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "conv1 = conv_layer(x, shape=[5, 5, 3, 64])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 64, 128])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*128])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, len(position_dict))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    X_batch, y_batch, file_name = test_img.get_batch(10)\n",
    "    test_accuracy = np.mean([sess.run(accuracy, feed_dict={x: X_batch, y_: y_batch, keep_prob: 1.0})])\n",
    "\n",
    "    print(\"test accuracy: {}\".format(test_accuracy))\n",
    "    \n",
    "    for i in range(len(os.listdir(test_path))):\n",
    "\n",
    "        X_batch, y_batch, file_name = test_img.get_batch(1)\n",
    "\n",
    "        label = y_batch\n",
    "        image_ar = X_batch[0]\n",
    "        if label_dict[np.argmax(sess.run(tf.nn.softmax(y_conv, 1),\n",
    "                                         feed_dict={x: X_batch,\n",
    "                                                    y_: y_batch, \n",
    "                                                    keep_prob: 1}))] != label_dict[np.argmax(label)]:\n",
    "            \n",
    "            print(label_dict[np.argmax(sess.run(\n",
    "                tf.nn.softmax(y_conv, 1), \n",
    "                feed_dict={x: X_batch, y_: y_batch, keep_prob: 1}))], file_name)\n",
    "            print(sess.run(tf.cast(y_conv, 1), feed_dict={x: X_batch, y_: y_batch, keep_prob: 1}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            ax1 = fig.add_subplot(1, 2, 1)\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('Pixel:\\n' + label_dict[np.argmax(label)])\n",
    "            ax1.imshow(image_ar);\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jeronimo/git/AUT-CNN-TUB/Data/Models/model_2018-08-12_01-42.ckpt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ebc6569ca9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use the saver object normally after that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1802\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1061\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    X_batch, y_batch, file_name = test_img.get_batch(10)\n",
    "    test_accuracy = np.mean([sess.run(accuracy, feed_dict={x: X_batch, y_: y_batch, keep_prob: 1.0})])\n",
    "\n",
    "    print(\"test accuracy: {}\".format(test_accuracy))\n",
    "    \n",
    "    for i in range(len(os.listdir(test_path))):\n",
    "\n",
    "        X_batch, y_batch, file_name = test_img.get_batch(1)\n",
    "\n",
    "        label = y_batch\n",
    "        image_ar = X_batch[0]\n",
    "        if label_dict[np.argmax(sess.run(tf.nn.softmax(y_conv, 1),\n",
    "                                         feed_dict={x: X_batch,\n",
    "                                                    y_: y_batch, \n",
    "                                                    keep_prob: 1}))] != label_dict[np.argmax(label)]:\n",
    "            \n",
    "            print(label_dict[np.argmax(sess.run(\n",
    "                tf.nn.softmax(y_conv, 1), \n",
    "                feed_dict={x: X_batch, y_: y_batch, keep_prob: 1}))], file_name)\n",
    "            print(sess.run(tf.cast(y_conv, 1), feed_dict={x: X_batch, y_: y_batch, keep_prob: 1}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            ax1 = fig.add_subplot(1, 2, 1)\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('Pixel:\\n' + label_dict[np.argmax(label)])\n",
    "            ax1.imshow(image_ar);\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(len(os.listdir(test_path)) * (1 - 0.999587893486023)),\n",
    "      'Fehler bei' ,\n",
    "      len(os.listdir(test_path)), \n",
    "      'Testbildern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load raw image for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4853"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home = os.getcwd().split('AUT-CNN-TUB')[0]\n",
    "test_path  = os.path.join(home,'AUT-CNN-TUB/Data/TF_Images_28/test/')\n",
    "data_path = os.path.join(test_path, '*g')  # ???\n",
    "\n",
    "files = glob.glob(data_path)\n",
    "num_imag = len(files)\n",
    "Data = np.arange(0, num_imag)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_tensorflow",
   "language": "python",
   "name": "python3_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
